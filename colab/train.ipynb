{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65575b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.load('train/x_train.pt')\n",
    "y = torch.load('train/y_train.pt')\n",
    "vocab = torch.load('train/vocab.pt')\n",
    "\n",
    "x.shape, y.shape, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code2vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(Code2vec, self).__init__()\n",
    "\n",
    "\n",
    "        self.embed_layer = nn.Embedding(vocab_size, 512, padding_idx=2)\n",
    "\n",
    "        self.final_layer = nn.Linear(2048, embedding_size)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    " \n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.residual_layer = nn.Sequential(\n",
    "            nn.MaxPool1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32768, 2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embed_layer(x)\n",
    "        x = x.permute(0, 2, 1) # 1, 256, 4096\n",
    "\n",
    "        residual = x\n",
    "\n",
    "\n",
    "        x = self.layers(x) + self.residual_layer(residual)\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "dataset = TensorDataset(x,y)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [0.95, 0.05])\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = Code2vec(len(vocab), 512)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "current_epoch = 0\n",
    "\n",
    "def calculate_accuracy(model, dataset, device, batch_size=BATCH_SIZE):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            pair_code1 = batch_x[:, 0, :].to(device)\n",
    "            pair_code2 = batch_x[:, 1, :].to(device)\n",
    "            batch_y = batch_y.to(device).float()\n",
    "            \n",
    "            cosine_sim = F.cosine_similarity(\n",
    "                model(pair_code1), \n",
    "                model(pair_code2), \n",
    "                dim=1\n",
    "            )\n",
    "            \n",
    "            predictions = torch.where(cosine_sim >= 0.8, 1.0, -1.0)\n",
    "            \n",
    "            correct += (predictions == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    model.train()\n",
    "    return correct / total * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "epoch_bar = tqdm(range(epochs), desc='Training')\n",
    "\n",
    "for epoch in epoch_bar:\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    batch_bar = tqdm(enumerate(loader), \n",
    "                    total=len(loader), \n",
    "                    desc=f'Epoch {current_epoch + epoch + 1}',\n",
    "                    leave=False)\n",
    "    \n",
    "    for i, batch in batch_bar:\n",
    "        batch_x, batch_y = batch\n",
    "        pair_code1 = batch_x[:, 0, :].to(device)\n",
    "        pair_code2 = batch_x[:, 1, :].to(device)\n",
    "        batch_y = batch_y.to(device).float()\n",
    "\n",
    "        pair1_output = model(pair_code1)\n",
    "        pair2_output = model(pair_code2)\n",
    "        \n",
    "        t = batch_y.clone()\n",
    "        \n",
    "        loss = criterion(pair1_output, pair2_output, t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        batch_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Avg': f'{running_loss/(i+1):.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(loader)\n",
    "    train_losses.append(avg_epoch_loss)  # 손실 기록\n",
    "    \n",
    "    train_acc = calculate_accuracy(model, train_dataset, device)\n",
    "    test_acc = calculate_accuracy(model, test_dataset, device)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f'Epoch {current_epoch + epoch + 1}: Train Accuracy: {train_acc:.2f}% | Test Accuracy: {test_acc:.2f}%')\n",
    "    \n",
    "\n",
    "    epoch_bar.set_postfix({\n",
    "        'Epoch Loss': f'{avg_epoch_loss:.4f}',\n",
    "        'Train Acc': f'{train_acc:.2f}',\n",
    "        'Test Acc': f'{test_acc:.2f}'\n",
    "    })\n",
    "\n",
    "current_epoch += epochs\n",
    "\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Total epochs trained: {current_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc115c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "if train_accuracies and test_accuracies:\n",
    "    epochs_range = range(1, len(train_accuracies) + 1)\n",
    "    plt.plot(epochs_range, train_accuracies, 'g-', marker='o', label='Train Accuracy')\n",
    "    plt.plot(epochs_range, test_accuracies, 'r-', marker='s', label='Test Accuracy')\n",
    "    plt.title('Train vs Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Train Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "if test_accuracies:\n",
    "    ax2.plot(range(1, len(test_accuracies) + 1), test_accuracies, 'r-', marker='o', label='Test Accuracy')\n",
    "    ax2.set_ylabel('Test Accuracy (%)', color='r')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels() if test_accuracies else ([], [])\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.title('Loss and Accuracy Over Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if train_losses:\n",
    "    print(f\"final loss: {train_losses[-1]:.4f}\")\n",
    "if train_accuracies:\n",
    "    print(f\"train acc: {train_accuracies[-1]:.2f}%\")\n",
    "if test_accuracies:\n",
    "    print(f\"test acc: {test_accuracies[-1]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94986551",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
